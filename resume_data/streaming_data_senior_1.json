Here is a highly realistic and original resume for a senior candidate in the field of streaming data:

```
{
  "name": "Rahul Kumar",
  "email": "rahul.kumar@example.com",
  "phone": "(123) 456-7890",
  "linkedin": "https://www.linkedin.com/in/rahulkumar/",
  "summary": "Results-driven Senior Architect with 10+ years of experience in designing and delivering large-scale real-time data pipelines. Skilled in Kafka, Spark Streaming, Flink, and event-driven architecture. Proven track record of leading cross-functional teams to achieve strategic objectives.",
  "experience": [
    {
      "title": "Senior Architect",
      "company": "DataCue Inc.",
      "duration": "2018 - Present (4 years)",
      "details": [
        "Designed and implemented a scalable real-time data pipeline using Apache Kafka, Spark Streaming, and Flink to process 100 million events daily.",
        "Led a team of 5 engineers to develop a cloud-native event-driven architecture for a Fortune 500 client, resulting in a 30% reduction in latency.",
        "Collaborated with stakeholders to define requirements and developed proof-of-concepts using window functions and Apache Spark for real-time analytics."
      ]
    },
    {
      "title": "Technical Lead",
      "company": "InnoVate Labs",
      "duration": "2015 - 2018 (3 years)",
      "details": [
        "Led a team of 10 engineers to develop a big data platform using Apache Hadoop and Spark, resulting in a 25% increase in data processing efficiency.",
        "Worked closely with the architecture team to design and implement a real-time data ingestion pipeline using Kafka and Flink for a financial services client.",
        "Mentored junior developers in Java, Scala, and Python programming languages."
      ]
    },
    {
      "title": "Senior Engineer",
      "company": "TechCorp Inc.",
      "duration": "2010 - 2015 (5 years)",
      "details": [
        "Contributed to the development of a real-time analytics platform using Apache Storm and Hadoop for a retail client, resulting in a 20% increase in sales forecasting accuracy.",
        "Collaborated with data scientists to design and implement data pipelines using Apache Pig and Hive for business intelligence reporting."
      ]
    }
  ],
  "education": {
    "degree": "Master of Science in Computer Science",
    "institution": "Stanford University",
    "year": "2010"
  },
  "skills": ["Kafka", "Spark Streaming", "Flink", "Apache Hadoop", "Java", "Scala", "Python", "Agile Development"],
  "certifications": []
}
```

